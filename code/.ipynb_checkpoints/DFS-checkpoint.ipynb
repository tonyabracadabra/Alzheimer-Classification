{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy import io as sio\n",
    "from tensorflow.python.framework import ops\n",
    "from dfs2 import DeepFeatureSelectionNew\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "data_All = sio.loadmat(\"/Volumes/TONY/LabWW/Alzheimer/GSE44772/GSE44772_data.mat\")\n",
    "\n",
    "data_PFC = sio.loadmat(\"/Volumes/TONY/LabWW/Alzheimer/GSE44772/GSE44772_PFC.mat\")\n",
    "data_VC = sio.loadmat(\"/Volumes/TONY/LabWW/Alzheimer/GSE44772/GSE44772_VC.mat\")\n",
    "data_CR = sio.loadmat(\"/Volumes/TONY/LabWW/Alzheimer/GSE44772/GSE44772_CR.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02759906, -0.02357416, -0.05874617, ..., -0.04292982,\n",
       "        -0.07279357,  0.1547638 ],\n",
       "       [-0.02049297,  0.00343816,  0.07269155, ..., -0.03786875,\n",
       "        -0.04625193,  0.2037762 ],\n",
       "       [ 0.1120596 ,  0.04373592, -0.1410087 , ..., -0.1232074 ,\n",
       "         0.05265946,  0.2035742 ],\n",
       "       ..., \n",
       "       [ 0.03262365,  0.02955401, -0.0803606 , ...,  0.07359058,\n",
       "        -0.06577679,  0.1283841 ],\n",
       "       [ 0.2279595 ,  0.07450501, -0.1902681 , ...,  0.03465823,\n",
       "        -0.06813613,  0.1920276 ],\n",
       "       [ 0.1316094 ,  0.06275084,  0.00191082, ..., -0.02948509,\n",
       "        -0.03494849,  0.1537997 ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_PFC['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1131188 ,  0.04840573,  0.00718927, ...,  0.04724792,\n",
       "        -0.06552072,  0.09849247],\n",
       "       [ 0.1865621 ,  0.02006223,  0.1537543 , ...,  0.01500595,\n",
       "        -0.1680981 ,  0.04561082],\n",
       "       [ 0.01420772,  0.02720214, -0.07076871, ..., -0.1804301 ,\n",
       "        -0.00367067,  0.179609  ],\n",
       "       ..., \n",
       "       [ 0.02368395,  0.1554557 ,  0.1553097 , ..., -0.1588447 ,\n",
       "        -0.1706083 ,  0.4649726 ],\n",
       "       [ 0.2141215 ,  0.09006891, -0.05755761, ...,  0.04024057,\n",
       "         0.00788023,  0.124734  ],\n",
       "       [ 0.1238284 ,  0.07975253,  0.07699472, ..., -0.08901209,\n",
       "        -0.04474195,  0.1858552 ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_VC['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setRegion(region):\n",
    "    if region == 'PFC':\n",
    "        ourdata = data_PFC\n",
    "    elif region == 'VC':\n",
    "        ourdata = data_VC\n",
    "    elif region == 'CR':\n",
    "        ourdata = data_CR\n",
    "    elif region == 'All':\n",
    "        ourdata = data_All\n",
    "        \n",
    "    inputX = ourdata['X']\n",
    "    # Inpute using median\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp.fit(inputX)\n",
    "    inputX = imp.transform(inputX)\n",
    "    \n",
    "    inputY = ourdata['y'][0,:]\n",
    "    \n",
    "    return inputX, inputY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputX, inputY = setRegion('CR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8380f605269f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-dcec1443e7f4>\u001b[0m in \u001b[0;36mig\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "ig(inputX, inputY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: global loss = 44.2518844604\n",
      "('Train accuracy:', 0.82608694)\n",
      "('Test accuracy:', 0.76086956)\n",
      "epoch 10: global loss = 10.9437866211\n",
      "('Train accuracy:', 0.93478262)\n",
      "('Test accuracy:', 0.84782606)\n",
      "epoch 20: global loss = 4.2828540802\n",
      "('Train accuracy:', 0.95108694)\n",
      "('Test accuracy:', 0.84782606)\n",
      "epoch 30: global loss = 1.71155512333\n",
      "('Train accuracy:', 0.97826087)\n",
      "('Test accuracy:', 0.84782606)\n",
      "epoch 40: global loss = 0.955415606499\n",
      "('Train accuracy:', 0.98369563)\n",
      "('Test accuracy:', 0.84782606)\n",
      "epoch 50: global loss = 0.666642308235"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(inputX, inputY, test_size=0.2, random_state=1)\n",
    "\n",
    "dfsMLP = DeepFeatureSelectionNew(X_train, X_test, y_train, y_test, n_input=1, hidden_dims=[100], dropout=[False], \\\n",
    "                                 learning_rate=0.01, lambda1=0.001, lambda2=1, alpha1=0.1, alpha2=0, activation='tanh', weight_init='uniform', \\\n",
    "                                 epochs=100, optimizer='Adam', print_step=10)\n",
    "\n",
    "dfsMLP.train(batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904520505705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "# All cross validation 0.900105526433\n",
    "# PFC cross validation 0.90895672731\n",
    "# VC cross validation 0.913401171755\n",
    "# CR cross validation 0.904520505705\n",
    "\n",
    "# keke, keke_test = topDFSfeatures(0,150)\n",
    "scores = cross_val_score(svm, inputX, inputY, cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allcross validation result:0.881546578956\n",
      "CRcross validation result:0.891380409086\n",
      "PFCcross validation result:0.900265186556\n",
      "VCcross validation result:0.878517833282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "rf = RandomForestClassifier(criterion=\"entropy\", n_estimators = 300, max_depth = 5)\n",
    "for region in ['All','CR','PFC','VC']:\n",
    "    inputX, inputY = setRegion(region)\n",
    "    scores = cross_val_score(rf, inputX, inputY, cv=5)\n",
    "    print(region + \"cross validation result:\" + str(np.mean(scores)))\n",
    "\n",
    "# gbm = xgb.XGBClassifier(max_depth=5, n_estimators=400, learning_rate=0.05).fit(top_train, y_train)\n",
    "# y_pred = gbm.predict(top_test)\n",
    "\n",
    "# featurescores = gbm.feature_importances_\n",
    "\n",
    "# print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR XGBoost cross validation result:0.882608695652\n",
      "PFC XGBoost cross validation result:0.882608695652\n",
      "VC XGBoost cross validation result:0.886956521739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# All XGBoost cross validation result:0.882608695652\n",
    "\n",
    "for region in ['CR','PFC','VC']:\n",
    "    inputX, inputY = setRegion(region)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf:\n",
    "        kf = KFold(n=inputX.shape[0], n_folds=5, shuffle=True, random_state=44)\n",
    "        X_train, X_test, y_train, y_test = inputX[train_index], inputX[test_index], inputY[train_index], inputY[test_index]\n",
    "        gbm = xgb.XGBClassifier(max_depth=5, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
    "        y_pred = gbm.predict(X_test)\n",
    "    #     featurescores = gbm.feature_importances_\n",
    "        scores.append(accuracy_score(y_test, y_pred))\n",
    "    print(region + \" XGBoost cross validation result:\" + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.cross_validation.KFold(n=230, n_folds=5, shuffle=True, random_state=44)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n=inputX.shape[0], n_folds=5, shuffle=True, random_state=44)\n",
    "\n",
    "kf\n",
    "\n",
    "1. MI\n",
    "2. Top 100\n",
    "3. GO analysis, pathway analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3   5   7   9  23  30  35  43  44  46  51  54  58  61  65  69  73  79\n",
      "  82  85  88 102 105 114 115 133 135 137 142 160 162 174 176 181 183 186\n",
      " 187 192 193 204 207 209 211 213 220 223]\n",
      "[  2   6  12  13  17  19  24  28  32  37  38  39  45  47  48  60  64  68\n",
      "  77  81  94  95 108 111 125 129 134 136 138 139 147 152 153 154 156 158\n",
      " 159 167 171 175 197 205 208 214 222 229]\n",
      "[  0  15  26  27  33  36  41  52  70  71  75  76  80  87  89  90  99 106\n",
      " 107 110 112 113 118 124 126 127 148 149 155 157 165 166 169 170 177 178\n",
      " 180 182 184 185 194 212 215 218 219 228]\n",
      "[  4   8  10  11  16  21  22  25  34  40  42  49  53  56  62  63  66  78\n",
      "  91  97  98 101 104 117 119 121 123 128 130 132 140 141 143 145 161 168\n",
      " 172 188 190 191 200 201 203 216 226 227]\n",
      "[  1  14  18  20  29  31  50  55  57  59  67  72  74  83  84  86  92  93\n",
      "  96 100 103 109 116 120 122 131 144 146 150 151 163 164 173 179 189 195\n",
      " 196 198 199 202 206 210 217 221 224 225]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf:\n",
    "    print test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = dfsMLP.selected_ws[0]\n",
    "index = np.argsort(abs(weight))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "101\n",
      "129\n",
      "101\n",
      "129\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(6):\n",
    "    print(len(inputY[inputY==i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topDFSfeatures(a,b):\n",
    "    return X_train[:, index.tolist()[a:b]], X_test[:, index.tolist()[a:b]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939955085306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "keke, keke_test = topDFSfeatures(0,150)\n",
    "scores = cross_val_score(svm, keke, y_train, cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905797101449\n",
      "0.898550724638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "top_train, top_test = topDFSfeatures(0,500)\n",
    "\n",
    "rf = RandomForestClassifier(criterion=\"entropy\", n_estimators = 300, max_depth = 5)\n",
    "rf.fit(top_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(top_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "gbm = xgb.XGBClassifier(max_depth=5, n_estimators=400, learning_rate=0.05).fit(top_train, y_train)\n",
    "y_pred = gbm.predict(top_test)\n",
    "\n",
    "featurescores = gbm.feature_importances_\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# gbm10 = xgb.XGBClassifier(max_depth=3, n_estimators=400, learning_rate=0.05).fit(X_train10, y_train)\n",
    "# y_pred10 = gbm.predict(X_test10)\n",
    "\n",
    "# print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(inputX, inputY, test_size=0.2, random_state=1)\n",
    "\n",
    "top_train, top_test = topDFSfeatures(20000,30000)\n",
    "\n",
    "dfsMLP = DeepFeatureSelectionNew(top_train, top_test, y_train, y_test, n_input=1, hidden_dims=[100], dropout=[False], \\\n",
    "                                 learning_rate=0.01, lambda1=0.001, lambda2=1, alpha1=0.01, alpha2=0, activation='tanh', weight_init='uniform', \\\n",
    "                                 epochs=100, optimizer='Adam', print_step=5)\n",
    "dfsMLP.train(batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "\n",
    "\n",
    "from math import log\n",
    "\n",
    "def I(p,n):\n",
    "\tpos = p / (p + n)\n",
    "\tneg = n / (p + n)\n",
    "\t\n",
    "\tif pos == 0 and neg == 0:\n",
    "\t\treturn 0\n",
    "\telif pos == 0:\n",
    "\t\treturn -neg * log(neg, 2)\n",
    "\telif neg == 0:\n",
    "\t\treturn -pos * log(pos, 2)\n",
    "\telse:\n",
    "\t\treturn (-pos * log(pos, 2)) + (-neg * log(neg, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
